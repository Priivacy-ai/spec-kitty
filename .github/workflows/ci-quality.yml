name: CI Quality

on:
  pull_request:
    branches:
      - develop
      - 2.x
  push:
    branches:
      - main
      - develop
      - 2.x
  workflow_dispatch:
    inputs:
      run_extended:
        description: 'Run integration/smoke suite'
        required: false
        default: false
        type: boolean

concurrency:
  group: ci-quality-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: read
  pull-requests: write

jobs:
  lint:
    runs-on: ubuntu-latest

    steps:
      - name: Check out repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: Set up Node
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .[test]

      - name: Install Node dependencies
        run: npm ci

      - name: Prepare report directories
        run: |
          mkdir -p out/reports/static-analysis
          mkdir -p out/reports/security

      - name: Determine commit range and cutoff date
        id: commit_range
        run: |
          # Set cutoff date for linting (when linting was introduced)
          CUTOFF_DATE="2026-02-25T00:00:00Z"
          echo "cutoff_date=$CUTOFF_DATE" >> "$GITHUB_OUTPUT"
          
          if [ "${{ github.event_name }}" = "pull_request" ]; then
            echo "from=${{ github.event.pull_request.base.sha }}" >> "$GITHUB_OUTPUT"
            echo "to=${{ github.event.pull_request.head.sha }}" >> "$GITHUB_OUTPUT"
          elif [ "${{ github.event_name }}" = "push" ] && [ "${{ github.event.before }}" != "0000000000000000000000000000000000000000" ]; then
            echo "from=${{ github.event.before }}" >> "$GITHUB_OUTPUT"
            echo "to=${{ github.sha }}" >> "$GITHUB_OUTPUT"
          fi

      - name: Run commit message linting
        id: commitlint
        if: always()
        continue-on-error: true
        run: |
          FROM_SHA="${{ steps.commit_range.outputs.from }}"
          TO_SHA="${{ steps.commit_range.outputs.to }}"
          CUTOFF_DATE="${{ steps.commit_range.outputs.cutoff_date }}"
          
          if [ -z "$FROM_SHA" ] || [ -z "$TO_SHA" ]; then
            echo "No commit range available for this trigger. Skipping commitlint."
            exit 0
          fi
          
          # Convert cutoff date to Unix timestamp for comparison
          CUTOFF_TIMESTAMP=$(date -d "$CUTOFF_DATE" +%s)
          
          # Get all commits in range
          mapfile -t ALL_COMMITS < <(git rev-list "$FROM_SHA..$TO_SHA")
          
          # Filter commits by cutoff date
          COMMITS_AFTER_CUTOFF=()
          for commit in "${ALL_COMMITS[@]}"; do
            commit_timestamp=$(git show -s --format=%ct "$commit")
            if [ "$commit_timestamp" -gt "$CUTOFF_TIMESTAMP" ]; then
              COMMITS_AFTER_CUTOFF+=("$commit")
            fi
          done
          
          if [ "${#COMMITS_AFTER_CUTOFF[@]}" -eq 0 ]; then
            echo "No commits after cutoff date ($CUTOFF_DATE). Skipping commitlint."
            exit 0
          fi
          
          # Run commitlint on filtered commits
          echo "Checking ${#COMMITS_AFTER_CUTOFF[@]} commits after cutoff date..."
          FAILED_COMMITS=""
          for commit in "${COMMITS_AFTER_CUTOFF[@]}"; do
            if ! echo "$commit" | npx --yes @commitlint/cli@19.8.1 \
              --config commitlint.config.cjs \
              --from "$commit~1" \
              --to "$commit" \
              --verbose; then
              commit_msg=$(git log --format=%s -n 1 "$commit")
              FAILED_COMMITS="${FAILED_COMMITS}${commit} - ${commit_msg}\n"
            fi
          done
          
          # Save failed commits for PR comment
          if [ -n "$FAILED_COMMITS" ]; then
            echo -e "$FAILED_COMMITS" > /tmp/commitlint-failures.txt
            echo "has_failures=true" >> "$GITHUB_OUTPUT"
            exit 1
          else
            echo "has_failures=false" >> "$GITHUB_OUTPUT"
          fi

      - name: Run markdown style linting on changed files
        id: markdownlint
        if: always()
        continue-on-error: true
        run: |
          FROM_SHA="${{ steps.commit_range.outputs.from }}"
          TO_SHA="${{ steps.commit_range.outputs.to }}"
          CUTOFF_DATE="${{ steps.commit_range.outputs.cutoff_date }}"
          
          if [ -z "$FROM_SHA" ] || [ -z "$TO_SHA" ]; then
            echo "No commit range available for this trigger. Skipping markdownlint."
            exit 0
          fi

          # Convert cutoff date to Unix timestamp for comparison
          CUTOFF_TIMESTAMP=$(date -d "$CUTOFF_DATE" +%s)

          mapfile -d '' CHANGED_MD_FILES < <(git diff --name-only -z --diff-filter=ACM "$FROM_SHA" "$TO_SHA" -- '*.md' '*.mdx')
          if [ "${#CHANGED_MD_FILES[@]}" -eq 0 ]; then
            echo "No changed markdown files in commit range."
            exit 0
          fi
          
          # Filter files by last modification date after cutoff
          FILES_TO_CHECK=()
          for file in "${CHANGED_MD_FILES[@]}"; do
            if [ -f "$file" ]; then
              # Get the last commit timestamp for this file in the range
              last_commit_timestamp=$(git log -1 --format=%ct "$FROM_SHA..$TO_SHA" -- "$file" 2>/dev/null || echo "0")
              if [ "$last_commit_timestamp" -gt "$CUTOFF_TIMESTAMP" ]; then
                FILES_TO_CHECK+=("$file")
              fi
            fi
          done
          
          if [ "${#FILES_TO_CHECK[@]}" -eq 0 ]; then
            echo "No markdown files modified after cutoff date ($CUTOFF_DATE)."
            exit 0
          fi
          
          echo "Checking ${#FILES_TO_CHECK[@]} markdown files modified after cutoff date..."
          
          # Run markdownlint and capture failures
          FAILED_FILES=""
          if ! npx --yes markdownlint-cli2@0.18.1 \
            --config .markdownlint-cli2.jsonc \
            "${FILES_TO_CHECK[@]}"; then
            for file in "${FILES_TO_CHECK[@]}"; do
              if ! npx --yes markdownlint-cli2@0.18.1 \
                --config .markdownlint-cli2.jsonc \
                "$file" 2>&1 >/dev/null; then
                FAILED_FILES="${FAILED_FILES}${file}\n"
              fi
            done
            echo -e "$FAILED_FILES" > /tmp/markdownlint-failures.txt
            echo "has_failures=true" >> "$GITHUB_OUTPUT"
            exit 1
          else
            echo "has_failures=false" >> "$GITHUB_OUTPUT"
          fi

      - name: Run ruff report
        id: ruff
        if: always()
        continue-on-error: true
        run: |
          python -m ruff check src tests | tee out/reports/static-analysis/ruff-report.txt

      - name: Run mypy report
        id: mypy
        if: always()
        continue-on-error: true
        run: |
          python -m mypy --strict src/specify_cli | tee out/reports/static-analysis/mypy-report.txt

      - name: Run Bandit security scan
        id: bandit
        if: always()
        continue-on-error: true
        run: |
          python -m bandit -r src/ \
            --severity-level medium \
            --confidence-level medium \
            | tee out/reports/security/bandit-report.txt

      - name: Run pip-audit CVE scan
        id: pip_audit
        if: always()
        continue-on-error: true
        run: |
          python -m pip_audit | tee out/reports/security/pip-audit-report.txt

      - name: Upload lint artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: lint-reports
          path: out/reports/

      - name: Post PR comment on linting failures
        if: always() && github.event_name == 'pull_request' && (steps.commitlint.outputs.has_failures == 'true' || steps.markdownlint.outputs.has_failures == 'true')
        uses: actions/github-script@v7
        with:
          script: |
            let comment = '## ‚ö†Ô∏è Linting Issues Detected\n\n';
            comment += 'The following linting issues were found in files/commits created after the cutoff date (2026-02-25):\n\n';
            
            // Check commitlint failures
            const commitlintFailed = '${{ steps.commitlint.outputs.has_failures }}' === 'true';
            if (commitlintFailed) {
              const fs = require('fs');
              let failedCommits = '';
              try {
                failedCommits = fs.readFileSync('/tmp/commitlint-failures.txt', 'utf8');
              } catch (e) {
                failedCommits = 'Unable to read commit failures';
              }
              comment += '### üìù Commit Message Issues\n\n';
              comment += 'The following commits do not follow the conventional commit format:\n\n';
              comment += '```\n' + failedCommits + '```\n\n';
            }
            
            // Check markdownlint failures
            const markdownlintFailed = '${{ steps.markdownlint.outputs.has_failures }}' === 'true';
            if (markdownlintFailed) {
              const fs = require('fs');
              let failedFiles = '';
              try {
                failedFiles = fs.readFileSync('/tmp/markdownlint-failures.txt', 'utf8');
              } catch (e) {
                failedFiles = 'Unable to read markdown failures';
              }
              comment += '### üìÑ Markdown Style Issues\n\n';
              comment += 'The following markdown files have style issues:\n\n';
              comment += '```\n' + failedFiles + '```\n\n';
            }
            
            comment += '**Note:** These are informational warnings and do not block the workflow. ';
            comment += 'Please address these issues when convenient.\n';
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });

      - name: Fail job if required checks failed
        if: always()
        run: |
          echo "commitlint outcome: ${{ steps.commitlint.outcome }}"
          echo "markdownlint outcome: ${{ steps.markdownlint.outcome }}"
          echo "ruff outcome: ${{ steps.ruff.outcome }}"
          echo "mypy outcome: ${{ steps.mypy.outcome }}"
          echo "bandit outcome: ${{ steps.bandit.outcome }}"
          echo "pip_audit outcome: ${{ steps.pip_audit.outcome }}"
          if [ "${{ steps.ruff.outcome }}" != "success" ] || \
             [ "${{ steps.mypy.outcome }}" != "success" ] || \
             [ "${{ steps.bandit.outcome }}" != "success" ] || \
             [ "${{ steps.pip_audit.outcome }}" != "success" ]; then
            echo "One or more checks failed."
            exit 1
          fi

  unit-tests:
    runs-on: ubuntu-latest
    # Run unit tests independently of lint job
    # This ensures test results are always available even if linting fails
    if: always()

    steps:
      - name: Check out repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .[test]

      - name: Prepare report directories
        run: |
          mkdir -p out/reports/xunit-reports
          mkdir -p out/reports/coverage

      - name: Run unit tests with coverage
        run: |
          python -m pytest \
            -v \
            tests/unit/ tests/contract/ \
            -m "not e2e and not slow and not distribution and not orchestrator_smoke" \
            --cov=src/specify_cli \
            --cov-report=term-missing \
            --cov-report=xml:out/reports/coverage/coverage.xml \
            --junitxml=out/reports/xunit-reports/xunit-result-unit-${{ github.run_id }}.xml

      - name: Enforce coverage policy
        run: |
          python - <<'PY'
          import xml.etree.ElementTree as ET

          report = ET.parse("out/reports/coverage/coverage.xml").getroot()
          pct = float(report.attrib["line-rate"]) * 100.0
          floor = 26.0
          print(f"Total coverage: {pct:.2f}% (floor: {floor:.2f}%)")
          if pct < floor:
              raise SystemExit(
                  f"Coverage floor not met: {pct:.2f}% < {floor:.2f}%"
              )
          PY

          if [ "${{ github.event_name }}" = "pull_request" ]; then
            diff-cover out/reports/coverage/coverage.xml \
              --compare-branch=origin/${{ github.base_ref }} \
              --fail-under=80
          else
            echo "Skipping diff coverage check outside pull_request events."
          fi

      - name: Upload unit test artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: unit-test-reports
          path: out/reports/

  cli-tests:
    runs-on: ubuntu-latest
    needs: unit-tests
    # Run even if unit-tests failed (to get full test results)
    if: always()

    steps:
      - name: Check out repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .[test]

      - name: Prepare report directories
        run: mkdir -p out/reports/xunit-reports

      - name: Run CLI tests
        run: |
          python -m pytest \
            -v \
            tests/specify_cli/ tests/adversarial/ tests/test_template/ \
            -m "not e2e and not slow and not distribution and not orchestrator_smoke" \
            --junitxml=out/reports/xunit-reports/xunit-result-cli-${{ github.run_id }}.xml

      - name: Upload CLI test artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: cli-test-reports
          path: out/reports/

  sync-tests:
    runs-on: ubuntu-latest
    needs: unit-tests
    # Run even if unit-tests failed (to get full test results)
    if: always()

    steps:
      - name: Check out repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .[test]

      - name: Prepare report directories
        run: mkdir -p out/reports/xunit-reports

      - name: Run sync tests
        run: |
          python -m pytest \
            -v \
            tests/sync/ \
            -m "not e2e and not slow and not distribution and not orchestrator_smoke" \
            --junitxml=out/reports/xunit-reports/xunit-result-sync-${{ github.run_id }}.xml

      - name: Upload sync test artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: sync-test-reports
          path: out/reports/

  integration-smoke:
    runs-on: ubuntu-latest
    needs: unit-tests
    # Only run on push or manual dispatch, but always run if triggered (even if unit-tests failed)
    if: always() && (github.event_name == 'push' || (github.event_name == 'workflow_dispatch' && inputs.run_extended))
    timeout-minutes: 45

    steps:
      - name: Check out repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .[test]

      - name: Prepare report directories
        run: |
          mkdir -p out/reports/xunit-reports
          mkdir -p out/reports/integration

      - name: Run integration and smoke tests
        run: |
          python -m pytest \
            -v \
            tests/integration \
            tests/e2e \
            -m "not distribution" \
            --junitxml=out/reports/xunit-reports/xunit-result-integration-${{ github.run_id }}.xml \
            | tee out/reports/integration/integration-smoke.log

      - name: Upload integration artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: integration-smoke-reports
          path: out/reports/

  dashboard-tests:
    runs-on: ubuntu-latest
    needs: unit-tests
    # Only run on push or manual dispatch, but always run if triggered (even if unit-tests failed)
    if: always() && (github.event_name == 'push' || (github.event_name == 'workflow_dispatch' && inputs.run_extended))

    steps:
      - name: Check out repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: Set up Node
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .[test]

      - name: Install Playwright browsers
        run: npx playwright install --with-deps chromium

      - name: Prepare report directories
        run: mkdir -p out/reports/xunit-reports

      - name: Run dashboard tests
        env:
          PWHEADLESS: '1'
        run: |
          python -m pytest \
            -v \
            tests/test_dashboard/ \
            -m "not e2e and not slow and not distribution and not orchestrator_smoke" \
            --junitxml=out/reports/xunit-reports/xunit-result-dashboard-${{ github.run_id }}.xml

      - name: Upload dashboard test artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: dashboard-test-reports
          path: out/reports/

  sonarcloud:
    runs-on: ubuntu-latest
    needs: unit-tests
    if: always()

    steps:
      - name: Check Sonar token availability
        id: sonar_token
        run: |
          if [ -n "${{ secrets.SONAR_TOKEN }}" ]; then
            echo "enabled=true" >> "$GITHUB_OUTPUT"
          else
            echo "enabled=false" >> "$GITHUB_OUTPUT"
            echo "SONAR_TOKEN is not configured; skipping SonarCloud steps."
          fi

      - name: Check out repository
        if: steps.sonar_token.outputs.enabled == 'true'
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Download coverage artifact
        if: steps.sonar_token.outputs.enabled == 'true' && needs.unit-tests.result == 'success'
        uses: actions/download-artifact@v4
        with:
          name: unit-test-reports
          path: out/reports

      - name: Normalize xUnit path for SonarCloud
        if: steps.sonar_token.outputs.enabled == 'true' && needs.unit-tests.result == 'success'
        run: |
          mkdir -p out/reports/xunit-reports
          latest_file="$(ls -1 out/reports/xunit-reports/xunit-result-unit-*.xml | head -n 1)"
          cp "$latest_file" out/reports/xunit-reports/xunit-result.xml

      - name: SonarCloud Scan
        if: steps.sonar_token.outputs.enabled == 'true' && needs.unit-tests.result == 'success'
        uses: SonarSource/sonarqube-scan-action@v6
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: SonarCloud Quality Gate
        if: steps.sonar_token.outputs.enabled == 'true' && needs.unit-tests.result == 'success'
        uses: SonarSource/sonarqube-quality-gate-action@v1.2.0
        timeout-minutes: 5
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
